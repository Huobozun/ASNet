import aedat
import numpy as np
import cv2
import h5py
import skimage.morphology as morpho
import matplotlib.pyplot as plt
import math
import numpy as np
import pandas as pd
import os

import random
import numpy as np
from PIL import Image
import torch


from datasets.utils import mvsecLoadRectificationMaps, mvsecRectifyEvents
from datasets.indices import *
from datasets.zdata_framedeal import CatchV, EventFrameIterator


# Intrinsics from MATLAB
distortionCoefficientsL = np.array([-0.2935,-0.3440,-1.7559e-04, -0.0015,1.5067])
cameraMatrixL = np.array([[789.3270,0.,332.1650],
[0.,789.9218,261.8494],
[0., 0., 1.]])
newCameraMatrixL = cameraMatrixL

distortionCoefficientsR = np.array([-0.3435,0.0741,-8.6562e-04,-9.9706e-04,0.4352])
cameraMatrixR = np.array([[788.2710,0.,324.8369],
[0.,788.6607,248.3408],[0.,0.,1.]])
newCameraMatrixR = cameraMatrixR

# Stereo params from MATLAB
Rot = np.array([[1.0000, 0.0011, 0.0090],[-0.0011, 1.0000, -4.9004e-04],[-0.0090, 4.8040e-04, 1.0000]]).T
Trns = np.array([[-62.5813], [-0.3437], [0.0488]])

	

def forthdataset(datapath,filename,save_frame):
	print("==========================\ndealing with data\n==========================")
	decoder=aedat.Decoder(datapath+'/'+filename)
	#initial time
	for packet in decoder:
		if(packet['stream_id']==0):  #left events
			if'events'in packet:
				
				timestart=list(packet['events'])[0][0]+1000000
				break
	
	#Set initial parameters
	timeunit=0.000001#Unit of time relative to seconds
	timestart=timestart*timeunit#The conversion unit is unified as seconds
	pointsv = 20#Sampling speed of data speed measurement
	timeslot = 0.1#The time slot involved in the stacks
	timefre = 0.05#Generate frame time interval
	timestamp=timestart#The time stamp when the frame is generated for the first time
	shape = [480,640]#h*w
	eventshape = [0,1,2,3]#Event Data Format
	Nsmall = 16
	Nbig = 64
	



	with open('./datasets/prepare4.txt','r') as file:
		item = file.readlines()
		sitem = item[0].split(' ')

	train_sensitivity = 141846.0 #The number of points generated by the training set 1s
	forth_sensitivity_l = float(sitem[1]) #The number of points generated in the left 1s of the test set
	forth_sensitivity_r = float(sitem[3]) #The number of points generated in the right 1s of the test set
	left_sensitivity = forth_sensitivity_l/train_sensitivity
	right_sensitivity = forth_sensitivity_r/train_sensitivity


	forth_sensitivity_l = forth_sensitivity_l/2
	forth_sensitivity_r = forth_sensitivity_r/2



	

	#Create a class that generates tensor
	eve_frame_l=EventFrameIterator(timestamp, timeslot, timefre, timeunit,  shape, forth_sensitivity_l, left_sensitivity, eventshape, Nsmall, Nbig, 'frameleft')
	eve_frame_r=EventFrameIterator(timestamp, timeslot, timefre, timeunit,  shape, forth_sensitivity_r, right_sensitivity, eventshape, Nsmall, Nbig, 'frameright')

    #begin generating
	frameL=[]
	listL=[]
	frameR=[]
	listR=[]
	i0=0
	i1 = 0
	i2 = 0
	fetch_size1 = 1
	fetch_slot1 = 0
	fetch_size2 = 1
	fetch_slot2 = 0
	for packet in decoder:
		if i0>=10000:
			if(packet['stream_id']==0):  #left events
				if'events'in packet:
					i1=0
					while(i1< len(list(packet['events']))):

						fetch_size_real1=min(fetch_size1,len(list(packet['events']))-i1)
					
	
						fetch_size1,fetch_slot1 = eve_frame_l._addevent_(fetch_size_real1,list(packet['events'])[int(i1):int(i1+fetch_size_real1)])
						

						i1+=fetch_size_real1+fetch_slot1

			elif(packet['stream_id']==1):  #right events
				if'events'in packet:
					i2=0
					while(i2< len(list(packet['events']))):

						fetch_size_real2=min(fetch_size2,len(list(packet['events']))-i2)
						
					
	
						fetch_size2,fetch_slot2 = eve_frame_r._addevent_(fetch_size_real2,list(packet['events'])[int(i2):int(i2+fetch_size_real2)])

						i2+=fetch_size_real2+fetch_slot2

			else:pass

               


		i0+=1

		if i0==14000:
			break
	frameL=eve_frame_l.frames
	frameR=eve_frame_r.frames
	listL=eve_frame_l.framelist
	listR=eve_frame_r.framelist


	imgSize = (640,480)

	R_L, R_R, proj_mat_l, proj_mat_r, Q, roiL, roiR= cv2.stereoRectify(newCameraMatrixL, distortionCoefficientsL, newCameraMatrixR, distortionCoefficientsR, imgSize, Rot, Trns, flags=cv2.CALIB_ZERO_DISPARITY, alpha=-1)

	leftMapX, leftMapY = cv2.initUndistortRectifyMap(newCameraMatrixL, distortionCoefficientsL, R_L, proj_mat_l, imgSize, cv2.CV_32FC1)
	rightMapX, rightMapY = cv2.initUndistortRectifyMap(newCameraMatrixR, distortionCoefficientsR, R_R, proj_mat_r, imgSize, cv2.CV_32FC1)



	if save_frame:
		if not os.path.exists(datapath+'/frameindoor_forth/rect/frameleft'):
			os.makedirs(datapath+'/frameindoor_forth/rect/frameleft')
		if not os.path.exists(datapath+'/frameindoor_forth/rect/frameright'):
			os.makedirs(datapath+'/frameindoor_forth/rect/frameright')
		if not os.path.exists(datapath+'/frameindoor_forth/frameleft'):
			os.makedirs(datapath+'/frameindoor_forth/frameleft')
		if not os.path.exists(datapath+'/frameindoor_forth/frameright'):
			os.makedirs(datapath+'/frameindoor_forth/frameright')

		for i in range(0,len(frameL)):
			Left_rectified = cv2.remap(frameL[i],leftMapX,leftMapY, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)
			cv2.imwrite(datapath+'/frameindoor_forth/frameleft/{}'.format(str(listL[i])),frameL[i])
			cv2.imwrite(datapath+'/frameindoor_forth/frameleft/{}.pfm'.format(str(listL[i]).replace('.jpg','')),frameL[i])
			cv2.imwrite(datapath+'/frameindoor_forth/rect/frameleft/{}'.format(str(listL[i])),Left_rectified)
			cv2.imwrite(datapath+'/frameindoor_forth/rect/frameleft/{}.pfm'.format(str(listL[i]).replace('.jpg','')),Left_rectified)
		for i in range(0,len(frameR)):
			Right_rectified = cv2.remap(frameR[i],rightMapX,rightMapY, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)
			cv2.imwrite(datapath+'/frameindoor_forth/frameright/{}'.format(str(listR[i])),frameR[i])
			cv2.imwrite(datapath+'/frameindoor_forth/frameright/{}.pfm'.format(str(listL[i]).replace('.jpg','')),frameR[i])
			cv2.imwrite(datapath+'/frameindoor_forth/rect/frameright/{}'.format(str(listR[i])),Right_rectified)
			cv2.imwrite(datapath+'/frameindoor_forth/rect/frameright/{}.pfm'.format(str(listL[i]).replace('.jpg','')),Right_rectified)
	


def mvsecdataset(datapath,  split_type, save_frame):
	print("==========================\ndealing with data\n==========================")
	frameL = []
	frameR = []
	depthL = []
	


	for ii0 in range(1,5):
		frameL.append([])
		frameR.append([])
		depthL.append([])

		
		data = h5py.File(datapath+'/indoor_flying{}_data.hdf5'.format(ii0))
		data1 = h5py.File(datapath+'/indoor_flying{}_gt.hdf5'.format(ii0))

		print(data['davis']['left'].keys())
		eve0=np.array(data['davis']['left']['events'])
		eve1=np.array(data['davis']['right']['events'])

		
	

		dep1=np.array(data1['davis']['left']['depth_image_rect'])
		ts1 =np.array(data1['davis']['left']['depth_image_rect_ts']) 
		
		for id in range(0,len(dep1)):

			filled = morpho.area_closing(dep1[id], area_threshold=24)
			depthL[ii0-1].append(filled)

		
		


		print(len(dep1))
	
		
		Lx_path = datapath+'/indoor_flying_left_x_map.txt'
		Ly_path = datapath+'/indoor_flying_left_y_map.txt'
		Rx_path = datapath+'/indoor_flying_right_x_map.txt'
		Ry_path = datapath+'/indoor_flying_right_y_map.txt'
		Lx_map, Ly_map, Rx_map, Ry_map = mvsecLoadRectificationMaps(Lx_path, Ly_path, Rx_path, Ry_path)
		rect_Levents = np.array(mvsecRectifyEvents(eve0, Lx_map, Ly_map)) 
		rect_Revents = np.array(mvsecRectifyEvents(eve1, Rx_map, Ry_map))
		




		timeunit = 1
		timestart=ts1[0]
		timeend=ts1[-1]
		timeslot = 0.1
		timefre = 0.05
		timestamp=timestart
		shape = [260,346]
		eventshape = [2,0,1,3]
		Nsmall = 16
		Nbig = 64


		with open('./datasets/prepare.txt','r') as file:
			item = file.readlines()
			sitem = item[0].split(' ')




		train_sensitivity = 227372.0 #The number of points generated by the training set 1s
		forth_sensitivity_l = float(sitem[1]) #The number of points generated in the left 1s of the test set
		forth_sensitivity_r = float(sitem[3]) #The number of points generated in the right 1s of the test set
		left_sensitivity = forth_sensitivity_l/train_sensitivity
		right_sensitivity = forth_sensitivity_r/train_sensitivity
	


		eve_frame_l=EventFrameIterator(timestamp, timeslot, timefre, timeunit, shape, forth_sensitivity_l, left_sensitivity, eventshape, Nsmall, Nbig, 'frameleft')
		eve_frame_r=EventFrameIterator(timestamp, timeslot, timefre, timeunit, shape, forth_sensitivity_r, right_sensitivity, eventshape, Nsmall, Nbig, 'frameright')


		i1 = 0
		i2 = 0
		fetch_size1 = 1
		fetch_slot1 = 0
		fetch_size2 = 1
		fetch_slot2 = 0

		while(i1 < len(rect_Levents)):

			fetch_size_real1=min(fetch_size1,len(rect_Levents)-i1)
	

			fetch_size1,fetch_slot1 = eve_frame_l._addevent_(fetch_size_real1,list(rect_Levents[int(i1):int(i1+fetch_size_real1)]))
			
			if(list(rect_Levents[int(i1)+int(fetch_size_real1)])[2]>timeend+0.02):#There are too many events, and the part without corresponding groundtruth is discarded
				break
			
			i1+=fetch_size_real1+fetch_slot1 
			
	
		
		
		while(i2 < len(rect_Revents)):

			fetch_size_real2=min(fetch_size2,len(rect_Revents)-i2)
			
			
			fetch_size2,fetch_slot2 = eve_frame_r._addevent_(fetch_size_real2, list(rect_Revents[int(i2):int(i2+fetch_size_real2)]))
			if(list(rect_Revents[int(i2)+int(fetch_size_real2)])[2]>timeend+0.02): 
				break

			i2+=fetch_size_real2+fetch_slot2
		
		frameL[ii0-1]+=eve_frame_l.frames
		frameR[ii0-1]+=eve_frame_r.frames
		

	if int(split_type) == 1:
		z1 = 139; y1 = 1201; z2 = 159; y2 = 1581; z3 = 124; y3 = 1816; z4 = 90; y4 = 360; ztrain1 = 1; ztrain2 = 2; zvaltest = 0; splittest = SPLIT1_TEST_INDICES; splitval = SPLIT1_VALID_INDICES
	elif int(split_type) == 2:
		z1 = 79; y1 = 1261; z2 = 119; y2 = 1421; z3 = 124; y3 = 1816; z4 = 90; y4 = 360; ztrain1 = 0; ztrain2 = 2; zvaltest = 1; splittest = SPLIT2_TEST_INDICES; splitval = SPLIT2_VALID_INDICES
	elif int(split_type) == 3:
		z1 = 79; y1 = 1261; z2 = 119; y2 = 1581; z3 = 72; y3 = 1816; z4 = 90; y4 = 360; ztrain1 = 0; ztrain2 = 1;zvaltest = 2; splittest = SPLIT3_TEST_INDICES; splitval = SPLIT3_VALID_INDICES
	else:
		z1 = 139; y1 = 1201; z2 = 159; y2 = 1581; z3 = 124; y3 = 1816; z4 = 90; y4 = 360; ztrain1 = 1; ztrain2 = 2; zvaltest = 0; splittest = SPLIT1_TEST_INDICES; splitval = SPLIT1_VALID_INDICES

	

	for ii1 in range(0,4):
		if ii1==0:
			tz=z1
			ty=y1
		elif ii1==1:
			tz=z2
			ty=y2
		elif ii1==2:
			tz=z3
			ty=y3
		elif ii1==3:
			tz=z4
			ty=y4
		frameL[ii1]=frameL[ii1][tz:ty]
		frameR[ii1]=frameR[ii1][tz:ty]
		depthL[ii1]=depthL[ii1][tz:ty]

	train_frameL = frameL[ztrain1]+frameL[ztrain2]
	train_frameR = frameR[ztrain1]+frameR[ztrain2]
	train_depthL = depthL[ztrain1]+depthL[ztrain2]
	val_frameL = torch.utils.data.Subset(frameL[zvaltest], splitval)
	val_frameR = torch.utils.data.Subset(frameR[zvaltest], splitval)
	val_depthL = torch.utils.data.Subset(depthL[zvaltest], splitval)
	test_frameL = torch.utils.data.Subset(frameL[zvaltest], splittest)
	test_frameR = torch.utils.data.Subset(frameR[zvaltest], splittest)
	test_depthL = torch.utils.data.Subset(depthL[zvaltest], splittest)





	if save_frame:

			
		if not os.path.exists(datapath+'/frameindoors'+split_type+'_mvsec3/TRAIN/depthleft'):
			os.makedirs(datapath+'/frameindoors'+split_type+'_mvsec3/TRAIN/depthleft')
		if not os.path.exists(datapath+'/frameindoors'+split_type+'_mvsec3/TRAIN/frameleft'):
			os.makedirs(datapath+'/frameindoors'+split_type+'_mvsec3/TRAIN/frameleft')
		if not os.path.exists(datapath+'/frameindoors'+split_type+'_mvsec3/TRAIN/frameright'):
			os.makedirs(datapath+'/frameindoors'+split_type+'_mvsec3/TRAIN/frameright')
		if not os.path.exists(datapath+'/frameindoors'+split_type+'_mvsec3/TEST/depthleft'):
			os.makedirs(datapath+'/frameindoors'+split_type+'_mvsec3/TEST/depthleft')
		if not os.path.exists(datapath+'/frameindoors'+split_type+'_mvsec3/TEST/frameleft'):
			os.makedirs(datapath+'/frameindoors'+split_type+'_mvsec3/TEST/frameleft')
		if not os.path.exists(datapath+'/frameindoors'+split_type+'_mvsec3/TEST/frameright'):
			os.makedirs(datapath+'/frameindoors'+split_type+'_mvsec3/TEST/frameright')
		if not os.path.exists(datapath+'/frameindoors'+split_type+'_mvsec3/VALID/depthleft'):
			os.makedirs(datapath+'/frameindoors'+split_type+'_mvsec3/VALID/depthleft')
		if not os.path.exists(datapath+'/frameindoors'+split_type+'_mvsec3/VALID/frameleft'):
			os.makedirs(datapath+'/frameindoors'+split_type+'_mvsec3/VALID/frameleft')
		if not os.path.exists(datapath+'/frameindoors'+split_type+'_mvsec3/VALID/frameright'):
			os.makedirs(datapath+'/frameindoors'+split_type+'_mvsec3/VALID/frameright')

		for i in range(0,len(train_frameL)):
			cv2.imwrite(datapath+'/frameindoors'+split_type+'_mvsec3/TRAIN/frameleft/{}.pfm'.format(str(i)),train_frameL[i])
			cv2.imwrite(datapath+'/frameindoors'+split_type+'_mvsec3/TRAIN/frameright/{}.pfm'.format(str(i)),train_frameR[i])
			cv2.imwrite(datapath+'/frameindoors'+split_type+'_mvsec3/TRAIN/depthleft/{}.pfm'.format(str(i)),train_depthL[i])
			

		for i in range(0,len(val_frameL)):
			cv2.imwrite(datapath+'/frameindoors'+split_type+'_mvsec3/VALID/frameleft/{}.pfm'.format(str(i)),val_frameL[i])
			cv2.imwrite(datapath+'/frameindoors'+split_type+'_mvsec3/VALID/frameright/{}.pfm'.format(str(i)),val_frameR[i])
			cv2.imwrite(datapath+'/frameindoors'+split_type+'_mvsec3/VALID/depthleft/{}.pfm'.format(str(i)),val_depthL[i])
			
		for i in range(0,len(test_frameL)):
			cv2.imwrite(datapath+'/frameindoors'+split_type+'_mvsec3/TEST/frameleft/{}.pfm'.format(str(i)),test_frameL[i])
			cv2.imwrite(datapath+'/frameindoors'+split_type+'_mvsec3/TEST/frameright/{}.pfm'.format(str(i)),test_frameR[i])
			cv2.imwrite(datapath+'/frameindoors'+split_type+'_mvsec3/TEST/depthleft/{}.pfm'.format(str(i)),test_depthL[i])
			
			





			